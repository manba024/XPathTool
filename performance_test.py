#!/usr/bin/env python3
"""
æ€§èƒ½å¯¹æ¯”æµ‹è¯•è„šæœ¬ - åŒæ­¥vså¼‚æ­¥æ¨¡å¼æ€§èƒ½å¯¹æ¯”
"""

import asyncio
import time
import sys
import os
import json
import psutil
import threading
from typing import List, Dict, Any
from datetime import datetime

# å¯¼å…¥åŒæ­¥å’Œå¼‚æ­¥æ¨¡å—
from batch_extractor import BatchXPathExtractor
from async_batch_extractor import AsyncBatchXPathExtractor
from config_manager import ConfigManager


class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = []
        
    def get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024
    
    def get_cpu_usage(self) -> float:
        """è·å–å½“å‰CPUä½¿ç”¨ç‡"""
        return psutil.cpu_percent(interval=0.1)
    
    def create_test_config(self, num_urls: int, use_async: bool = True) -> Dict[str, Any]:
        """åˆ›å»ºæµ‹è¯•é…ç½®"""
        # åˆ›å»ºæµ‹è¯•URLåˆ—è¡¨ï¼ˆä½¿ç”¨ä¸åŒçš„URLè¿›è¡Œæµ‹è¯•ï¼‰
        test_urls = [
            "https://httpbin.org/html",
            "https://httpbin.org/json",
            "https://jsonplaceholder.typicode.com/posts/1",
            "https://jsonplaceholder.typicode.com/posts/2",
            "https://jsonplaceholder.typicode.com/posts/3",
        ]
        
        # å¦‚æœéœ€è¦æ›´å¤šURLï¼Œé‡å¤ä½¿ç”¨ä½†æ·»åŠ ä¸åŒçš„å‚æ•°
        urls = []
        for i in range(num_urls):
            url = test_urls[i % len(test_urls)]
            if i >= len(test_urls):
                url += f"?test={i}"  # æ·»åŠ å‚æ•°ä½¿URLä¸åŒ
            urls.append(url)
        
        config = {
            "max_concurrent": 5 if use_async else 3,  # å¼‚æ­¥ä½¿ç”¨æ›´é«˜å¹¶å‘
            "request_timeout": 30,
            "llm_timeout": 60,
            "retry_count": 1,  # å‡å°‘é‡è¯•ä»¥åŠ å¿«æµ‹è¯•
            "output_file": f"test_results_{'async' if use_async else 'sync'}.csv",
            "model": "Pro/deepseek-ai/DeepSeek-R1",
            "use_async": use_async,
            "max_http_concurrent": 10 if use_async else 5,
            "max_llm_concurrent": 3 if use_async else 2,
            "batch_size": 5,
            "connection_pool_size": 50,
            "target_elements": ["æ ‡é¢˜", "å†…å®¹"],
            "urls": urls,
            "output_format": {
                "include_content_preview": True,
                "max_content_length": 100,
                "include_element_count": True,
                "include_processing_time": True
            }
        }
        
        return config
    
    async def run_async_test(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå¼‚æ­¥æµ‹è¯•"""
        print("å¼€å§‹å¼‚æ­¥æ¨¡å¼æµ‹è¯•...")
        
        start_time = time.time()
        start_memory = self.get_memory_usage()
        start_cpu = self.get_cpu_usage()
        
        try:
            # åˆå§‹åŒ–å¼‚æ­¥æå–å™¨
            extractor = AsyncBatchXPathExtractor(config)
            
            # è·å–æµ‹è¯•å‚æ•°
            urls = config["urls"]
            target_elements = config["target_elements"]
            
            # è¿è¡Œå¼‚æ­¥æ‰¹é‡å¤„ç†
            results = await extractor.process_batch_async(urls, target_elements)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            end_time = time.time()
            end_memory = self.get_memory_usage()
            end_cpu = self.get_cpu_usage()
            
            total_time = end_time - start_time
            total_urls = len(urls)
            successful_urls = sum(1 for r in results if r['status'] == 'success')
            
            return {
                "mode": "async",
                "total_urls": total_urls,
                "successful_urls": successful_urls,
                "total_time": total_time,
                "qps": total_urls / total_time if total_time > 0 else 0,
                "avg_time_per_url": total_time / total_urls if total_urls > 0 else 0,
                "memory_usage": end_memory - start_memory,
                "cpu_usage": end_cpu,
                "max_concurrent": config["max_concurrent"],
                "results": results
            }
            
        except Exception as e:
            print(f"å¼‚æ­¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return {
                "mode": "async",
                "error": str(e),
                "total_urls": len(config["urls"]),
                "successful_urls": 0,
                "total_time": 0,
                "qps": 0,
                "avg_time_per_url": 0,
                "memory_usage": 0,
                "cpu_usage": 0
            }
    
    def run_sync_test(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡ŒåŒæ­¥æµ‹è¯•"""
        print("å¼€å§‹åŒæ­¥æ¨¡å¼æµ‹è¯•...")
        
        start_time = time.time()
        start_memory = self.get_memory_usage()
        start_cpu = self.get_cpu_usage()
        
        try:
            # åˆå§‹åŒ–åŒæ­¥æå–å™¨
            extractor = BatchXPathExtractor(config)
            
            # è·å–æµ‹è¯•å‚æ•°
            urls = config["urls"]
            target_elements = config["target_elements"]
            
            # è¿è¡ŒåŒæ­¥æ‰¹é‡å¤„ç†
            results = extractor.process_batch(urls, target_elements)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            end_time = time.time()
            end_memory = self.get_memory_usage()
            end_cpu = self.get_cpu_usage()
            
            total_time = end_time - start_time
            total_urls = len(urls)
            successful_urls = sum(1 for r in results if r['status'] == 'success')
            
            return {
                "mode": "sync",
                "total_urls": total_urls,
                "successful_urls": successful_urls,
                "total_time": total_time,
                "qps": total_urls / total_time if total_time > 0 else 0,
                "avg_time_per_url": total_time / total_urls if total_urls > 0 else 0,
                "memory_usage": end_memory - start_memory,
                "cpu_usage": end_cpu,
                "max_concurrent": config["max_concurrent"],
                "results": results
            }
            
        except Exception as e:
            print(f"åŒæ­¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return {
                "mode": "sync",
                "error": str(e),
                "total_urls": len(config["urls"]),
                "successful_urls": 0,
                "total_time": 0,
                "qps": 0,
                "avg_time_per_url": 0,
                "memory_usage": 0,
                "cpu_usage": 0
            }
    
    async def run_comparison_test(self, num_urls: int = 10) -> Dict[str, Any]:
        """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
        print(f"å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼Œæµ‹è¯•URLæ•°é‡: {num_urls}")
        print("=" * 60)
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        async_config = self.create_test_config(num_urls, use_async=True)
        sync_config = self.create_test_config(num_urls, use_async=False)
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        async_result = await self.run_async_test(async_config)
        
        # è¿è¡ŒåŒæ­¥æµ‹è¯•
        sync_result = self.run_sync_test(sync_config)
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        comparison = self.generate_comparison_report(async_result, sync_result)
        
        return {
            "test_info": {
                "num_urls": num_urls,
                "test_time": datetime.now().isoformat(),
                "system_info": {
                    "cpu_count": psutil.cpu_count(),
                    "memory_total": psutil.virtual_memory().total / 1024 / 1024 / 1024,
                    "platform": sys.platform
                }
            },
            "async_result": async_result,
            "sync_result": sync_result,
            "comparison": comparison
        }
    
    def generate_comparison_report(self, async_result: Dict[str, Any], sync_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        comparison = {}
        
        # QPSå¯¹æ¯”
        if async_result["qps"] > 0 and sync_result["qps"] > 0:
            comparison["qps_improvement"] = (async_result["qps"] / sync_result["qps"] - 1) * 100
            comparison["qps_ratio"] = async_result["qps"] / sync_result["qps"]
        
        # å¤„ç†æ—¶é—´å¯¹æ¯”
        if async_result["avg_time_per_url"] > 0 and sync_result["avg_time_per_url"] > 0:
            comparison["time_improvement"] = (sync_result["avg_time_per_url"] / async_result["avg_time_per_url"] - 1) * 100
            comparison["time_ratio"] = sync_result["avg_time_per_url"] / async_result["avg_time_per_url"]
        
        # å†…å­˜ä½¿ç”¨å¯¹æ¯”
        if async_result["memory_usage"] > 0 and sync_result["memory_usage"] > 0:
            comparison["memory_improvement"] = (sync_result["memory_usage"] / async_result["memory_usage"] - 1) * 100
            comparison["memory_ratio"] = sync_result["memory_usage"] / async_result["memory_usage"]
        
        # æˆåŠŸç‡å¯¹æ¯”
        if async_result["successful_urls"] > 0 and sync_result["successful_urls"] > 0:
            async_success_rate = async_result["successful_urls"] / async_result["total_urls"] * 100
            sync_success_rate = sync_result["successful_urls"] / sync_result["total_urls"] * 100
            comparison["success_rate_diff"] = async_success_rate - sync_success_rate
        
        return comparison
    
    def print_test_results(self, results: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\n" + "=" * 60)
        print("æ€§èƒ½æµ‹è¯•ç»“æœ")
        print("=" * 60)
        
        # ç³»ç»Ÿä¿¡æ¯
        sys_info = results["test_info"]["system_info"]
        print(f"æµ‹è¯•æ—¶é—´: {results['test_info']['test_time']}")
        print(f"æµ‹è¯•URLæ•°é‡: {results['test_info']['num_urls']}")
        print(f"CPUæ ¸å¿ƒæ•°: {sys_info['cpu_count']}")
        print(f"æ€»å†…å­˜: {sys_info['memory_total']:.1f} GB")
        print(f"å¹³å°: {sys_info['platform']}")
        
        # å¼‚æ­¥ç»“æœ
        async_result = results["async_result"]
        print(f"\nğŸš€ å¼‚æ­¥æ¨¡å¼ç»“æœ:")
        print(f"  å¤„ç†URLæ•°: {async_result['total_urls']}")
        print(f"  æˆåŠŸURLæ•°: {async_result['successful_urls']}")
        print(f"  æ€»è€—æ—¶: {async_result['total_time']:.2f}ç§’")
        print(f"  QPS: {async_result['qps']:.2f}")
        print(f"  å¹³å‡æ¯URLæ—¶é—´: {async_result['avg_time_per_url']:.2f}ç§’")
        print(f"  å†…å­˜ä½¿ç”¨: {async_result['memory_usage']:.2f} MB")
        print(f"  CPUä½¿ç”¨ç‡: {async_result['cpu_usage']:.1f}%")
        print(f"  æœ€å¤§å¹¶å‘: {async_result['max_concurrent']}")
        
        # åŒæ­¥ç»“æœ
        sync_result = results["sync_result"]
        print(f"\nğŸ”„ åŒæ­¥æ¨¡å¼ç»“æœ:")
        print(f"  å¤„ç†URLæ•°: {sync_result['total_urls']}")
        print(f"  æˆåŠŸURLæ•°: {sync_result['successful_urls']}")
        print(f"  æ€»è€—æ—¶: {sync_result['total_time']:.2f}ç§’")
        print(f"  QPS: {sync_result['qps']:.2f}")
        print(f"  å¹³å‡æ¯URLæ—¶é—´: {sync_result['avg_time_per_url']:.2f}ç§’")
        print(f"  å†…å­˜ä½¿ç”¨: {sync_result['memory_usage']:.2f} MB")
        print(f"  CPUä½¿ç”¨ç‡: {sync_result['cpu_usage']:.1f}%")
        print(f"  æœ€å¤§å¹¶å‘: {sync_result['max_concurrent']}")
        
        # å¯¹æ¯”ç»“æœ
        comparison = results["comparison"]
        print(f"\nğŸ“Š æ€§èƒ½æå‡:")
        if "qps_improvement" in comparison:
            print(f"  QPSæå‡: {comparison['qps_improvement']:.1f}% ({comparison['qps_ratio']:.1f}x)")
        if "time_improvement" in comparison:
            print(f"  å¤„ç†æ—¶é—´å‡å°‘: {comparison['time_improvement']:.1f}% ({comparison['time_ratio']:.1f}x)")
        if "memory_improvement" in comparison:
            print(f"  å†…å­˜ä½¿ç”¨å‡å°‘: {comparison['memory_improvement']:.1f}% ({comparison['memory_ratio']:.1f}x)")
        if "success_rate_diff" in comparison:
            print(f"  æˆåŠŸç‡å·®å¼‚: {comparison['success_rate_diff']:.1f}%")
        
        print("=" * 60)
    
    def save_test_results(self, results: Dict[str, Any], output_file: str = "performance_test_results.json"):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {str(e)}")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ€§èƒ½å¯¹æ¯”æµ‹è¯•')
    parser.add_argument('--urls', type=int, default=10, help='æµ‹è¯•URLæ•°é‡')
    parser.add_argument('--output', type=str, default='performance_test_results.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜æµ‹è¯•ç»“æœ')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv('SILICONFLOW_API_KEY'):
        print("è­¦å‘Š: æœªè®¾ç½®ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY")
        print("è¯·è®¾ç½®APIå¯†é’¥: export SILICONFLOW_API_KEY='your_api_key_here'")
        return
    
    # è¿è¡Œæµ‹è¯•
    tester = PerformanceTester()
    results = await tester.run_comparison_test(args.urls)
    
    # æ‰“å°ç»“æœ
    tester.print_test_results(results)
    
    # ä¿å­˜ç»“æœ
    if not args.no_save:
        tester.save_test_results(results, args.output)


if __name__ == "__main__":
    asyncio.run(main())