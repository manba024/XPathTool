# XPath智能提取工具

## 功能介绍

这个工具可以自动分析网页结构，使用大语言模型（LLM）智能提取指定元素的XPath表达式。

## 核心特性

- 🤖 **智能分析**: 使用DeepSeek等大模型理解网页语义
- 🎯 **精准提取**: 生成稳定、准确的XPath表达式  
- ✅ **自动验证**: 实时验证XPath有效性
- 🚀 **简单易用**: 命令行一键操作

## 安装依赖

```bash
pip install -r requirements.txt
```

## 配置API密钥

设置硅基流动API密钥环境变量：

```bash
export SILICONFLOW_API_KEY='your_api_key_here'
```

## 使用方法

### 1. 命令行方式

```bash
python3 xpath_extractor.py <URL> <元素1> [元素2] [元素3] ...
```

**示例：**
```bash
python3 xpath_extractor.py https://www.jiangsu.gov.cn/art/2025/7/16/art_46144_11602534.html 标题 正文
```

### 2. Python脚本方式

```python
from xpath_extractor import XPathExtractor

# 初始化提取器
extractor = XPathExtractor()

# 执行提取
results = extractor.extract_xpath(
    url="https://example.com", 
    target_elements=["标题", "正文"]
)

# 输出结果
for element_name, result in results['xpath_results'].items():
    if result['found']:
        print(f"{url} + {element_name} + {result['xpath']}")
```

## 输出格式

工具会输出以下格式的结果：

```
URL + 数据名称 + XPath表达式
```

例如：
```
https://www.jiangsu.gov.cn/art/2025/7/16/art_46144_11602534.html + 标题 + //h1[@class='title']
https://www.jiangsu.gov.cn/art/2025/7/16/art_46144_11602534.html + 正文 + //div[@class='content']//p
```

## 技术原理

1. **网页获取**: 使用requests获取目标网页HTML
2. **DOM清理**: 使用BeautifulSoup清理和结构化HTML
3. **智能分析**: 使用LLM分析DOM结构和语义
4. **XPath生成**: 基于语义理解生成稳定的XPath
5. **结果验证**: 使用lxml验证XPath有效性

## 优势对比

相比传统方法，这个工具有以下优势：

- ✅ **智能理解**: 能理解页面语义，不仅仅是结构
- ✅ **自适应**: 对页面结构变化有更好的适应性
- ✅ **高效**: 一次性提取多个元素
- ✅ **准确**: LLM分析比简单规则更准确

## 注意事项

- 需要稳定的网络连接访问LLM API
- 对于动态加载的内容可能需要额外处理
- API调用有成本，建议合理使用